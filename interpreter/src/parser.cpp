/**
 * @file parser.cpp
 * @brief Parser implementation for the Roscript interpreter.
 *
 * This file contains the implementation of the parser for the Roscript interpreter. It includes functions to parse expressions, variable declarations, and error handling.
 * It's header contains the definitions of the AST nodes and the parser functions.
 * @see parser.h
 * 
 * IMPORTANT
 * This is the description of the parse_rhs_expression function, which is the core of the parser. It handles operator precedence and associativity, and recursively parses right-hand side expressions.
 * @image html prhse.png
 *
 * @author Rares-Cosma
 * @date 2025-04-25
 */
#include "parser.h"
#include "errors.h"
#include "commons.cpp"
#include "ansi.h"

struct Token {
	int line_nb;
	string line;
	string value;
	string type;
};

/**
 * @class TokenStream
 * @brief A class to handle the tokens generated by the lexer.
 * @note This class stores the raw tokens and the number of tokens per line, and reconstructs lines for error reporting.
 */

class TokenStream {
public:
    std::vector<std::pair<std::string, std::string>> raw_tokens; // {type, value} 
    std::vector<Token> tokens;                                   // final token list

    void init(vector<int> tokens_per_line) {
        /**
         * @brief Initializes the TokenStream by using tokens_per_line to build each token's line context and number.
         * @note This function assumes that tokens_per_line aligns exactly with the number of logical lines in the source code.
         */
        size_t token_index = 0;
        int line_number = 1;

        for (int count : tokens_per_line) {
            std::vector<std::string> current_line_texts;
            std::string full_line;

            for (int i = 0; i < count; ++i) {
                if (token_index >= raw_tokens.size()) break;

                auto [type, value] = raw_tokens[token_index++];
                current_line_texts.push_back(value);
            }

            full_line = join(current_line_texts, " ");

            for (int i = 0; i < count; ++i) {
                const auto& [type, value] = raw_tokens[token_index - count + i];
                tokens.push_back({line_number, full_line, value, type});
            }

            line_number++;
        }
    }

private:
    std::string join(const std::vector<std::string>& words, const std::string& sep) {
        std::string result;
        for (size_t i = 0; i < words.size(); ++i) {
            result += words[i];
            if (i + 1 < words.size()) result += sep;
        }
        return result;
    }
};


// ABSTRACT SYNTAX TREE IMPLEMEMTATION

vector<ASTNode*> AST; // vector of AST nodes
vector<string> parser_variables; // vector of variables
vector<string> parser_user_defined_fn; // vector of user defined functions

// PARSER IMPLEMENTATION

int get_precedence(const std::string& op) {
    if (op == "||") return 0;
    if (op == "&&") return 1;
    if (op == "==" || op == "!=") return 2;
    if (op == "<" || op == ">" || op == "<=" || op == ">=") return 3;
    if (op == "+" || op == "-") return 4;
    if (op == "*" || op == "/" || op == "%") return 5;
    return -1;
}

Expr* parse_expression(const vector<Token>& tokens, int& idx);

Expr* parse_primary_expression(const vector<Token>& tokens, int& idx) {

	/**
 	* @brief Parses the simplest elements of an expression (literals and variable references).
 	* @param tokens The tokens to parse.
 	* @param idx The current index in the tokens vector.
 	* @return The coresponding derived expression.
	 */

	if (tokens[idx].type == "OP" && (tokens[idx].value == "-" || tokens[idx].value == "!")) {
    	string op = tokens[idx].value;
    	idx++; // consume operator
    	Expr* operand = parse_primary_expression(tokens, idx);
    	if (!operand) {
        	throw Error(
    			colorize("Eroare de expresie 001: ", Color::Red, 0) + 
    			"Expresie asteptata dupa operatorul unar '" + op + "'",
    			CURRENT_FILE,
    			tokens[idx].line_nb,
    			tokens[idx].line);
    	}
    	return new UnaryExpr(op, operand);
	}

    if (idx >= tokens.size()) return nullptr;

    if (tokens[idx].type == "INT") {
        int value = stoi(tokens[idx].value);
        idx++;
        return new IntLiteral(value);
    }
    else if (tokens[idx].type == "FLOAT") {
        float value = stof(tokens[idx].value);
        idx++;
        return new FloatLiteral(value);
    }
    else if (tokens[idx].type == "STRING") {
        string value = tokens[idx].value;
        idx++;
        return new StringLiteral(value);
    }
	else if (tokens[idx].type == "BOOL") {
		bool value = (tokens[idx].value == "adevarat" || tokens[idx].value == "true");
		idx++;
		return new BoolLiteral(value);
	}
    else if (tokens[idx].type == "ID") {
        string name = tokens[idx].value;
        idx++;
        if (idx < tokens.size() && tokens[idx].type == "LPAREN") {
        	if (stdlib.find(name) != stdlib.end()) {
            	idx++;
            	vector<Expr*> args;

        		while (idx < tokens.size() && tokens[idx].type != "RPAREN") {
                	args.push_back(parse_expression(tokens,idx));
                	if (tokens[idx].type == "COMMA") idx++; // consume ',' between args
            	}

            	if (idx >= tokens.size() || tokens[idx].type != "RPAREN") {
                	throw Error(
    					colorize("Eroare de parsare 001: ", Color::Red, 0) + 
    					"Paranteza inchisa ')' asteptata dupa argumentele functiei standard",
    					CURRENT_FILE,
    					tokens[idx].line_nb,
    					tokens[idx].line);
            	}
            	idx++;

            	return new FunctionCall(name, args);
        	} else if (find(parser_user_defined_fn.begin(), parser_user_defined_fn.end(), name) != parser_user_defined_fn.end()) {
            	idx++;
            	vector<Expr*> args;

        		while (idx < tokens.size() && tokens[idx].type != "RPAREN") {
                	args.push_back(parse_expression(tokens,idx));
                	if (tokens[idx].type == "COMMA") idx++; // consume ',' between args
            	}

            	if (idx >= tokens.size() || tokens[idx].type != "RPAREN") {
                	throw Error(
    					colorize("Eroare de parsare 001: ", Color::Red, 0) + 
    					"Paranteza inchisa ')' asteptata dupa argumentele functiei definite de utilizator",
    					CURRENT_FILE,
    					tokens[idx].line_nb,
    					tokens[idx].line);
            	}
            	idx++;

            	return new FunctionCall(name, args);
        	}
		} else if (idx < tokens.size() && tokens[idx].type == "LBRACKET") {
			idx++; // consume [
			vector<Expr*> indexes;
			while (idx < tokens.size() && tokens[idx].type != "RBRACKET")
			{
				Expr* indexExpr = parse_expression(tokens, idx);
				if (tokens[idx].type == "COMMA") idx++; // consume ','
				if (!indexExpr) {
					throw Error(
						colorize("Eroare de expresie 001: ", Color::Red, 0) + 
						"Expresie asteptata pentru indexul listei",
						CURRENT_FILE,
						tokens[idx].line_nb,
						tokens[idx].line);
				}
				indexes.push_back(indexExpr);
			}
			idx++;
			if (find(parser_variables.begin(), parser_variables.end(), name) != parser_variables.end()) {
				return new ListIndex(name, indexes);
			} else {
				throw Error(
					colorize("Eroare de semantica 001: ", Color::Red, 0) + 
					"Variabila '" + name + "' nu a fost declarata",
					CURRENT_FILE,
					tokens[idx].line_nb,
					tokens[idx].line);
			}
		} else {
			return new Refrence(name);
		}
	} else if (tokens[idx].value == "[") {
		vector<Expr*> elements;
		int ct_index=0;
		idx++; // consume [
		while (idx < tokens.size() && tokens[idx].type != "RBRACKET")
		{
			Expr* element = parse_expression(tokens, idx);
			if (!element) {
				throw Error(
					colorize("Eroare de expresie 002: ", Color::Red, 0) + 
					"Parsarea expresiei elementului de lista a esuat la indexul " + std::to_string(ct_index),
					CURRENT_FILE,
					tokens[idx].line_nb,
					tokens[idx].line);
			}
			elements.push_back(element);
			ct_index++;
			if (idx < tokens.size() && tokens[idx].type == "COMMA") idx++; // consume ','
		}
		idx++; //consume ;
		return new ListLiteral(elements, ct_index);
	} else if (tokens[idx].type == "LPAREN") {
        idx++; // consume (
        Expr* expr = parse_expression(tokens, idx);
        if (idx >= tokens.size() || tokens[idx].type != "RPAREN") {
            throw Error(
    			colorize("Eroare de parsare 001: ", Color::Red, 0) + 
    			"Paranteza inchisa ')' asteptata dupa expresie",
    			CURRENT_FILE,
    			tokens[idx].line_nb,
    			tokens[idx].line);
            return nullptr;
        }
        idx++; // consume )
        return expr;
    }
	
    return nullptr;
}

Expr* parse_rhs_expression(int expr_prec, Expr* lhs, const vector<Token>& tokens, int& idx) {
	/**
 	* @brief Parses right-hand expression.
 	* @param expr_prec The current expression precedence.
	* @param lhs The left-hand side expression.
	* @param tokens The tokens to parse.
 	* @param idx The current index in the tokens vector.
	* @note This function is the core to our parser, because it handles the precedence of the operators and the associativity. It is recursive and will call itself to parse the right-hand side expression.
 	* @return BinaryExpr combining the left and right expressions.
	 */

	while (idx < tokens.size()) {
        if (tokens[idx].type != "OP") return lhs;
        string op = tokens[idx].value;
        int prec = get_precedence(op);

        if (prec < expr_prec) break;

        idx++; // consume operator
        Expr* rhs = parse_primary_expression(tokens, idx);
        if (!rhs) return nullptr;

        while (idx < tokens.size() && tokens[idx].type == "OP" &&
               get_precedence(tokens[idx].value) > prec) {
            rhs = parse_rhs_expression(get_precedence(tokens[idx].value), rhs, tokens, idx);
        }

        lhs = new BinaryExpr(lhs, op, rhs);
    }


    return lhs;
}

Expr* parse_expression(const vector<Token>& tokens, int& idx) {
	/**
 	* @brief Parses an expression and returns the corresponding AST node.
 	* @param tokens The tokens to parse.
 	* @param idx The current index in the tokens vector.
 	* @return The parsed expression as an AST node.
	 */
	if (idx >= tokens.size()) return nullptr;
	Expr* left = parse_primary_expression(tokens, idx);
	if (!left) return nullptr;

	return parse_rhs_expression(0, left, tokens, idx);
}

vector<ASTNode*> parse_block(vector<Token> tokens, int& idx);

/*void report_error(const string& msg, const string& line, int line_nb) {
	/**
 	* @brief Thows custom syntax errors.
 	* @param line The line of the error.
 	* @param line_nb The line number in the source code.
 	* @return Prints the error message and the line of code.
	 */
	/*
	cerr << "Syntax Error: " << msg << "\nOn line: ";
	cout << line_nb << ": ";
	cout << line;
	cerr << "\n\n";
}*/

void parse_return_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a return statement declaration line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the variable declaration to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++;

	if (idx<tokens.size()) {
		Expr* expr = parse_expression(tokens, idx);
		if (expr) {
			ASTNode* node = new ReturnStatement(expr);
			AST.push_back(node);
			if (idx < tokens.size() && tokens[idx].type == "NLINE") idx++; // consume new line
		} else {
			throw Error(
    			colorize("Eroare de expresie 002: ", Color::Red, 0) + 
    			"Parsarea expresiei dupa 'return' a esuat",
    			CURRENT_FILE,
    			start_line_nb,
    			start_line);
		}
	} else {
		throw Error(
    		colorize("Eroare de expresie 001: ", Color::Red, 0) + 
    		"Expresie asteptata dupa 'return'",
    		CURRENT_FILE,
    		start_line_nb,
    		start_line);
	}
}

void parse_variable_declaration(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a variable declaration line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the variable declaration to the AST.
 	* @note Because "var" is not a type spefcific keyword, we cannot determine the type of the variable, in case it has no initializer so we add it to the NDT stack (non determined) and relocate it later.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	string type=tokens[idx].value;
	idx++;

	if (tokens[idx].type != "ID") {
		throw Error(
    		colorize("Eroare de parsare 001: ", Color::Red, 0) + 
    		"Numele variabilei asteptat dupa tipul '" + type + "'",
    		CURRENT_FILE,
    		start_line_nb,
    		start_line);
		return;
	}

	string name=tokens[idx].value;
	idx++;

	if (idx<tokens.size() && (tokens[idx].type=="NLINE"||tokens[idx].type=="COMMA"||tokens[idx].value==";"||tokens[idx].value==")")) {
		ASTNode* node = nullptr;
		if (type=="var"){
			Expr* default_value = new IntLiteral(0);
        	node = new VariableDeclaration("NDT", name, default_value);
		} else if (type=="intreg"){
			Expr* default_value = new IntLiteral(0);
        	node = new VariableDeclaration("INT", name, default_value);
		} else if (type=="real"){
			Expr* default_value = new FloatLiteral(0.0f);
			node = new VariableDeclaration("FLOAT", name, default_value);
		} else if (type=="sirc"){
			Expr* default_value = new StringLiteral("");
			node = new VariableDeclaration("STRING", name, default_value);
		} else if (type=="logic"){
			Expr* default_value = new BoolLiteral(false);
			node = new VariableDeclaration("BOOL", name, default_value);
		} else {
			throw Error(
    			colorize("Eroare de tip 001: ", Color::Red, 0) + 
    			"Tip necunoscut '" + type + "'",
    			CURRENT_FILE,
    			start_line_nb,
    			start_line);
			return;
		}
		
		parser_variables.push_back(name); // add variable to the list of variables
        AST.push_back(node);
		idx++;
	} else if (idx<tokens.size()) {
		idx++;
		Expr* expr = parse_expression(tokens, idx);
		if (expr) {
			ASTNode* node = nullptr;
			if (type=="var"){
				node = new VariableDeclaration("NDT", name, expr);
			} else if (type=="intreg"){
				node = new VariableDeclaration("INT", name, expr);
			} else if (type=="real"){
				node = new VariableDeclaration("FLOAT", name, expr);
			} else if (type=="sirc"){
				node = new VariableDeclaration("STRING", name, expr);
			} else if (type=="logic"){
				node = new VariableDeclaration("BOOL", name, expr);
			} else {
				throw Error(
    				colorize("Eroare de tip 001: ", Color::Red, 0) + 
    				"Tip necunoscut '" + type + "'",
    				CURRENT_FILE,
    				start_line_nb,
    				start_line);
				return;
			}
			parser_variables.push_back(name); // add variable to the list of variables
			AST.push_back(node);
			idx++;
		} else {
			throw Error(
    			colorize("Eroare de expresie 002: ", Color::Red, 0) + 
    			"Parsarea expresiei dupa declararea variabilei '" + name + "' a esuat",
    			CURRENT_FILE,
    			start_line_nb,
    			start_line);
		}
	}
}

void parse_assignment_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses an assignment statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the assignment statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	bool list=false;
	vector<Expr*> indexes;
	string name=tokens[idx].value;
	idx++; // consume variable name
	if (tokens[idx].type == "LBRACKET") {
		idx++; // consume [
		while (idx < tokens.size() && tokens[idx].type != "RBRACKET") {
			Expr* indexExpr = parse_expression(tokens, idx);
			if (!indexExpr) {
				throw Error(
					colorize("Eroare de expresie 001: ", Color::Red, 0) + 
					"Expresie asteptata pentru indexul listei",
					CURRENT_FILE,
					tokens[idx].line_nb,
					tokens[idx].line);
			}
			indexes.push_back(indexExpr);
			if (tokens[idx].type == "COMMA") idx++; // consume ','
		}
		idx++; // consume ]
		list = true;
	}

	if (tokens[idx].value == "--") {
		// handle decrement operator
		if (parser_variables.empty() || find(parser_variables.begin(), parser_variables.end(), name) == parser_variables.end()) {
			throw Error(
    			colorize("Eroare de semantica 001: ", Color::Red, 0) + 
    			"Variabila '" + name + "' nu a fost declarata.",
    			CURRENT_FILE,
    			start_line_nb,
    			start_line);
			return;
		}
		ASTNode* node = nullptr;
		if (list) {node = new AssignStatement(new BinaryExpr(new ListIndex(name,indexes), "-", new IntLiteral(1)), name, 1, indexes);}
		else node = new AssignStatement(new BinaryExpr(new Refrence(name), "-", new IntLiteral(1)), name, 0, indexes);
		AST.push_back(node);
		idx+=2;
		return;
	} else if (tokens[idx].value == "++") {
		// handle increment operator
		if (parser_variables.empty() || find(parser_variables.begin(), parser_variables.end(), name) == parser_variables.end()) {
			throw Error(
    			colorize("Eroare de semantica 001: ", Color::Red, 0) + 
    			"Variabila '" + name + "' nu a fost declarata.",
    			CURRENT_FILE,
    			start_line_nb,
    			start_line);
			return;
		}
		ASTNode* node = nullptr;
		if (list) {node = new AssignStatement(new BinaryExpr(new ListIndex(name,indexes), "+", new IntLiteral(1)), name, 1, indexes);}
		else node = new AssignStatement(new BinaryExpr(new Refrence(name), "+", new IntLiteral(1)), name, 0, indexes);
		AST.push_back(node);
		idx+=2;
		return;
	} else if (tokens[idx].value == "+=") {
		// handle add operator
		if (parser_variables.empty() || find(parser_variables.begin(), parser_variables.end(), name) == parser_variables.end()) {
			throw Error(
    			colorize("Eroare de semantica 001: ", Color::Red, 0) + 
    			"Variabila '" + name + "' nu a fost declarata.",
    			CURRENT_FILE,
    			start_line_nb,
    			start_line);
			return;
		}
		idx++; // consume '+=' operator
		ASTNode* node = nullptr;
		if (list) {node = new AssignStatement(new BinaryExpr(new ListIndex(name,indexes), "+", parse_expression(tokens, idx)), name, 1, indexes);}
		else node = new AssignStatement(new BinaryExpr(new Refrence(name), "+", parse_expression(tokens, idx)), name, 0, indexes);
		AST.push_back(node);
		idx++; // consume new line
		return;
	} else if (tokens[idx].value == "-=") {
		// handle subtract operator
		if (parser_variables.empty() || find(parser_variables.begin(), parser_variables.end(), name) == parser_variables.end()) {
			throw Error(
    			colorize("Eroare de semantica 001: ", Color::Red, 0) + 
    			"Variabila '" + name + "' nu a fost declarata.",
    			CURRENT_FILE,
    			start_line_nb,
    			start_line);
			return;
		}
		idx++; // consume '-=' operator
		ASTNode* node = nullptr;
		if (list) {node = new AssignStatement(new BinaryExpr(new ListIndex(name,indexes), "-", parse_expression(tokens, idx)), name, 1, indexes);}
		else node = new AssignStatement(new BinaryExpr(new Refrence(name), "-", parse_expression(tokens, idx)), name, 0, indexes);
		AST.push_back(node);
		idx++; // consume new line
		return;
	} else if (tokens[idx].value == "*=") {
		// handle multiply operator
		if (parser_variables.empty() || find(parser_variables.begin(), parser_variables.end(), name) == parser_variables.end()) {
			throw Error(
    			colorize("Eroare de semantica 001: ", Color::Red, 0) + 
    			"Variabila '" + name + "' nu a fost declarata.",
    			CURRENT_FILE,
    			start_line_nb,
    			start_line);
			return;
		}
		idx++; // consume '*=' operator
		ASTNode* node = nullptr;
		if (list) { node = new AssignStatement(new BinaryExpr(new ListIndex(name,indexes), "*", parse_expression(tokens, idx)), name, 1, indexes);}
		else node = new AssignStatement(new BinaryExpr(new Refrence(name), "*", parse_expression(tokens, idx)), name, 0, indexes);
		AST.push_back(node);
		idx++; // consume new line
		return;
	} else if (tokens[idx].value == "/=") {
		// handle divide operator
		if (parser_variables.empty() || find(parser_variables.begin(), parser_variables.end(), name) == parser_variables.end()) {
			throw Error(
    			colorize("Eroare de semantica 001: ", Color::Red, 0) + 
    			"Variabila '" + name + "' nu a fost declarata.",
    			CURRENT_FILE,
    			start_line_nb,
    			start_line);
			return;
		}
		idx++; // consume '/=' operator
		ASTNode* node = nullptr;
		if (list) {node = new AssignStatement(new BinaryExpr(new ListIndex(name,indexes), "/", parse_expression(tokens, idx)), name, 1, indexes);}
		else node = new AssignStatement(new BinaryExpr(new Refrence(name), "/", parse_expression(tokens, idx)), name, 0, indexes);
		AST.push_back(node);
		idx++; // consume new line
		return;
	}
	idx++; // consume '=' operator

	if (idx<tokens.size()) {
		Expr* expr = parse_expression(tokens, idx);
		ASTNode* node = nullptr;
		if (list) {node = new AssignStatement(expr, name, 1, indexes);}
		else node = new AssignStatement(expr, name, 0, indexes);
		
		AST.push_back(node);
		idx++;
		return;
	} else {
		throw Error(
    		colorize("Eroare de expresie 001: ", Color::Red, 0) + 
    		"Expresie asteptata dupa semnul '='",
    		CURRENT_FILE,
    		start_line_nb,
    		start_line);
		return;
	}
}

void parse_fc_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses an assignment statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the assignment statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	string name=tokens[idx].value;
	idx++; // consume function name

	if (idx<tokens.size() && tokens[idx].type=="LPAREN") {
		idx++; // consume '('
		vector<Expr*> args;
		while (idx < tokens.size() && tokens[idx].type != "RPAREN") {
			Expr* arg = parse_expression(tokens, idx);
			if (arg) {
				args.push_back(arg);
			} else {
				throw Error(
    				colorize("Eroare de expresie 001: ", Color::Red, 0) + 
    				"Expresie asteptata in lista de argumente a functiei '" + name + "'",
    				CURRENT_FILE,
    				start_line_nb,
    				start_line);
				return;
			}
			if (idx < tokens.size() && tokens[idx].type == "COMMA") {
				idx++; // consume ','
			}
		}
		ASTNode* node = new FunctionCall(name, args);
		AST.push_back(node);
		idx+=2;
		return;
	} else {
		throw Error(
    		colorize("Eroare de parsare 001: ", Color::Red, 0) + 
    		"Paranteza deschisa '(' asteptata dupa numele functiei '" + name + "'",
    		CURRENT_FILE,
    		start_line_nb,
    		start_line);
		return;
	}
}

void parse_print_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a print statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the print statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++;

	if (idx<tokens.size()) {
		ASTNode* node = new PrintStatement(parse_expression(tokens, idx));
		AST.push_back(node);
		idx++;
		return;
	} else {
		throw Error(
			colorize("Eroare de expresie 001: ", Color::Red, 0) + 
			"Expresie asteptata dupa 'afiseaza'",
			CURRENT_FILE,
			start_line_nb,
			start_line);
		return;
	}
}

vector<ASTNode*> functionDefinitions;

void parse_fd_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a function definition statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the function definition statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++;

	if (idx<tokens.size() && tokens[idx].type=="ID") {
		string name=tokens[idx].value;
		parser_user_defined_fn.push_back(name);
		vector<ASTNode*> args, block;
		idx++;
		if (tokens[idx].type != "LPAREN"){
			throw Error(
				colorize("Eroare de parsare 001: ", Color::Red, 0) + 
				"Paranteza deschisa '(' asteptata dupa numele functiei '" + name + "'",
				CURRENT_FILE,
				start_line_nb,
				start_line);
		}
		idx++;
		while (idx<tokens.size()){
			parse_variable_declaration(tokens,idx,args);
			if (tokens[idx].value!="var") break;
		}
		block=parse_block(tokens,idx);
		ASTNode* node=new FunctionDefinition(name,args,block);
		AST.push_back(node);
		functionDefinitions.push_back(node);
		return;
	} else {
		throw Error(
			colorize("Eroare de parsare 001: ", Color::Red, 0) + 
			"Numele functiei asteptat dupa 'functie'",
			CURRENT_FILE,
			start_line_nb,
			start_line);
		return;
	}
}


void parse_input_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a input statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the input statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++;

	if (idx<tokens.size() && tokens[idx].type=="ID") {
		ASTNode* node = new InputStatement(tokens[idx].value);
		AST.push_back(node);
		idx+=2;
		return;
	} else {
		throw Error(
			colorize("Eroare de expresie 001: ", Color::Red, 0) + 
			"Expresie asteptata dupa 'citeste'",
			CURRENT_FILE,
			start_line_nb,
			start_line);
		return;
	}
}

void parse_for_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a for statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the for statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++; // consume "pentru"

	if (tokens[idx].type != "LPAREN") {
		throw Error(
			colorize("Eroare de parsare 001: ", Color::Red, 0) + 
			"Paranteza deschisa '(' asteptata dupa 'pentru'",
			CURRENT_FILE,
			start_line_nb,
			start_line);
		return;
	}

	idx++; // consume '('

	vector<ASTNode*> init_block; // initialization block
	Expr* condition = nullptr; // loop condition

	if (tokens[idx].type == "KEYWORD" && tokens[idx].value == "var") {
		parse_variable_declaration(tokens, idx, init_block); // parse variable declaration
	} else if (tokens[idx].type == "ID") {
		parse_assignment_statement(tokens, idx, init_block); // parse assignment statement
	} else {
		throw Error(
			colorize("Eroare de parsare 001: ", Color::Red, 0) + 
			"Variabila sau declaratie de variabila asteptata dupa 'pentru ('",
			CURRENT_FILE,
			start_line_nb,
			start_line);
		return;
	}

	condition = parse_expression(tokens, idx); // parse loop condition
	
	if (tokens[idx].value == ";"){
		idx++; // consume ';'
	} else {
		throw Error(
			colorize("Eroare de semantica 002: ", Color::Red, 0) + 
			"Punct si virgula ';' asteptat dupa conditia de bucla",
			CURRENT_FILE,
			start_line_nb,
			start_line);
		return;
	}

	if (tokens[idx].type == "ID") {
		parse_assignment_statement(tokens, idx, init_block); // parse assignment statement
	} else {
		throw Error(
			colorize("Eroare de parsare 001: ", Color::Red, 0) + 
			"Atribuire asteptata dupa conditia de bucla",
			CURRENT_FILE,
			start_line_nb,
			start_line);
		return;
	}

	if (tokens[idx].value=="executa"){ // support for "executa" keyword
		idx++; // consume "executa"
	}

	vector<ASTNode*> block = parse_block(tokens, idx); // main for block
	if (block.empty()) {
		throw Error(
			colorize("Eroare de parsare 001: ", Color::Red, 0) + 
			"Bloc de instructiuni asteptat dupa 'pentru'/'executa'",
			CURRENT_FILE,
			start_line_nb,
			start_line);
		return;
	}

	ASTNode* node = new ForStatement(init_block[0], condition, block, init_block[1]);
	AST.push_back(node);
	return;
}

void parse_while_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a while statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the while statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++; // cat keyword

	if (tokens[idx].value == "timp") { // support for "timp" keyword
		idx++; // consume "timp"
	}

	if (idx<tokens.size() && tokens[idx].type=="LPAREN") {
		Expr* condition = parse_expression(tokens, idx);
		if (tokens[idx].value=="executa"){ // support for "executa" keyword
			idx++; // consume "executa"
		}
		vector<ASTNode*> block = parse_block(tokens, idx); // main while block
		ASTNode* node = new WhileStatement(condition, block);
		AST.push_back(node);
		return;
	} else {
		throw Error(
			colorize("Eroare de parsare 001: ", Color::Red, 0) + 
			"Paranteza deschisa '(' asteptata dupa 'cat timp'",
			CURRENT_FILE,
			start_line_nb,
			start_line);
		return;
	}
}

void parse_do_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a do while/until statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the do while/until statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++; // repeta keyword

	vector<ASTNode*> block; // main do while block
	block = parse_block(tokens, idx); // parse the block
	if (block.empty()) {
		throw Error(
			colorize("Eroare de parsare 001: ", Color::Red, 0) + 
			"Bloc de instructiuni asteptat dupa 'repeta'",
			CURRENT_FILE,
			start_line_nb,
			start_line);
		return;
	}

	if (tokens[idx].value == "cat") { // support for "cat" keyword
		idx++; // consume "cat"
		if (tokens[idx].value == "timp") { // support for "timp" keyword
			idx++; // consume "timp"
		}
		
		Expr* condition = parse_expression(tokens, idx);
		if (tokens[idx].value==";") { // support for ";" at the end of the statement
			idx++; // consume ";"
		} else {
			throw Error(
				colorize("Eroare de parsare 001: ", Color::Red, 0) + 
				"Punct si virgula ';' asteptat dupa conditia de bucla",
				CURRENT_FILE,
				start_line_nb,
				start_line);
			return;
		}
		
		ASTNode* node = new DoWhileStatement(condition, block);
		AST.push_back(node);
		return;
	} else if (tokens[idx].value == "pana") { // support for "pana" keyword
		idx++; // consume "pana"
		if (tokens[idx].value == "cand") { // support for "cand" keyword
			idx++; // consume "cand"
		}
		Expr* condition = parse_expression(tokens, idx);
		
		if (tokens[idx].value==";") { // support for ";" at the end of the statement
			idx++; // consume ";"
		} else {
			throw Error(
				colorize("Eroare de parsare 001: ", Color::Red, 0) + 
				"Punct si virgula ';' asteptat dupa conditia de bucla",
				CURRENT_FILE,
				start_line_nb,
				start_line);
			return;
		}
		ASTNode* node = new DoUntilStatement(condition, block);
		AST.push_back(node);
		return;
	} else {
		throw Error(
			colorize("Eroare de parsare 001: ", Color::Red, 0) + 
			"'cat timp'/'pana cand' asteptat dupa 'repeta'",
			CURRENT_FILE,
			start_line_nb,
			start_line);
		return;
	}
}

void parse_if_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses an if statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the if statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++;

	if (idx<tokens.size() && tokens[idx].type=="LPAREN") {
		Expr* condition = parse_expression(tokens, idx);
		if (tokens[idx].value=="atunci"){ // support for "atunci" keyword
			idx++; // consume "atunci"
		}

		vector<ASTNode*> block = parse_block(tokens, idx); // main if block
		vector<ASTNode*> else_block; // else block
		vector<pair<Expr*, vector<ASTNode*>>> elseif_branches; // else if branches

		while (idx < tokens.size() && tokens[idx].type == "KEYWORD" && tokens[idx].value == "altfel") {
			idx++; // consume "altfel"
			if (idx < tokens.size() && tokens[idx].value == "daca") {
				idx++; // consume "daca"
				Expr* elseif_condition = parse_expression(tokens, idx);
				if (tokens[idx].value == "atunci") { // support for "atunci" keyword
					idx++; // consume "atunci"
				}
				vector<ASTNode*> elseif_block = parse_block(tokens, idx);
				elseif_branches.push_back({elseif_condition, elseif_block});
			} else {
				if (tokens[idx].type == "LBRACE") {
					else_block = parse_block(tokens, idx); // else block
				} else if (tokens[idx].value == "atunci") {
					idx++; // consume "atunci"
					if (tokens[idx].type == "LBRACE") {
						else_block = parse_block(tokens, idx); // else block
					} else {
						throw Error(
							colorize("Eroare de parsare 001: ", Color::Red, 0) + 
							"Paranteza deschisa '{' asteptata dupa 'altfel atunci'",
							CURRENT_FILE,
							start_line_nb,
							start_line);
						return;
					}
				} else {
					throw Error(
						colorize("Eroare de parsare 001: ", Color::Red, 0) + 
						"Paranteza deschisa '{' asteptata dupa 'altfel'",
						CURRENT_FILE,
						start_line_nb,
						start_line);
					return;
				}
			}
		}
		ASTNode* node = new IfStatement(condition, block, elseif_branches, else_block);
		AST.push_back(node);
		return;
	}
}

vector<ASTNode*> parse(vector<pair<string, string>> tokens, vector<int> tokens_per_line) {
	/**
 	* @brief Parses the tokens and creates the AST.
 	* @param tokens The tokens to parse.
 	* @return The AST.
 	* @note This function is the main entry point for the parser. It takes the tokens generated by the lexer and creates the AST.
	 */

	TokenStream stream;
	stream.raw_tokens = tokens;
	stream.init(tokens_per_line);

	int idx = 0; // token counter

	while (idx<stream.tokens.size()){
		string& type=stream.tokens[idx].type;
		string& value=stream.tokens[idx].value;
		//cout<< "Parsing token: " << value << " of type: " << type << endl;
		if (type == "KEYWORD" && (value == "var" || value == "intreg" || value == "real" || value == "sirc" || value == "logic")) {
			parse_variable_declaration(stream.tokens, idx, AST); // parse variable declaration
		/*} else if (type == "KEYWORD" && value == "afiseaza") {
			parse_print_statement(stream.tokens, idx, AST); // parse print statement
		} else if (type == "KEYWORD" && value == "citeste") {
			parse_input_statement(stream.tokens, idx, AST); // parse print statement */
		} else if (type == "ID" && find(parser_variables.begin(),parser_variables.end(),value)!= parser_variables.end()) {
			parse_assignment_statement(stream.tokens, idx, AST); // parse assignment statement
		} else if (type == "ID" && (stdlib.find(value) != stdlib.end()||find(parser_user_defined_fn.begin(),parser_user_defined_fn.end(),value)!=parser_user_defined_fn.end())) {
			parse_fc_statement(stream.tokens, idx, AST); // parse FunctionCall statement
		} else if (type == "KEYWORD" && value == "functie") {
			parse_fd_statement(stream.tokens,idx,AST); // parse FunctionDeclaration statement
		} else if (type == "KEYWORD" && value == "daca") {
			parse_if_statement(stream.tokens, idx, AST); // parse if statement
		} else if (type == "KEYWORD" && value == "returneaza") {
			parse_return_statement(stream.tokens, idx, AST); // parse return statement
		} else if (type == "KEYWORD" && value == "cat") {
			parse_while_statement(stream.tokens, idx, AST); // parse while statement
		} else if (type == "KEYWORD" && value == "pentru") {
			parse_for_statement(stream.tokens, idx, AST); // parse for statement
		} else if (type == "KEYWORD" && value == "repeta") {
			parse_do_statement(stream.tokens,idx,AST); // parse do statement
		} else {
			throw Error(
				colorize("Eroare de parsare 002: ", Color::Red, 0) + 
				"Token neasteptat: '" + value + "'",
				CURRENT_FILE,
				stream.tokens[idx].line_nb,
				stream.tokens[idx].line);
			idx++; // skip the unexpected token
		}
	}

	return AST;
}

vector<ASTNode*> parse_block(vector<Token> tokens, int& idx) {
	/**
 	* @brief Parses the tokens and creates the AST for a block of code.
 	* @param idx The current index in the tokens vector.
 	* @param tokens The tokens to parse.
 	* @return The AST of the block.
	 */

	if (idx >= tokens.size() || tokens[idx].type != "LBRACE") {
		throw Error(
			colorize("Eroare de parsare 001: ", Color::Red, 0) + 
			"Paranteza deschisa '{' asteptata la inceputul blocului",
			CURRENT_FILE,
			tokens[idx].line_nb,
			tokens[idx].line);
		return {};
	}
	idx++; // consume '{'
	int ct = 1; // brace counter

	vector<ASTNode*> ASTb; // AST for the block

	while (idx<tokens.size()){
		string& type=tokens[idx].type;
		string& value=tokens[idx].value;
		if (type == "RBRACE") { 
			ct--;
			if (ct==0) {
				idx++; // consume '}'
				return ASTb; // end of block
			}
			idx++; // consume '}'
		}
		if (type == "LBRACE") {
			ct++;
		}
		if (type == "KEYWORD" && (value == "var" || value == "int" || value == "float" || value == "string" || value == "bool")) {
			parse_variable_declaration(tokens, idx, ASTb); // parse variable declaration
		/*} else if (type == "KEYWORD" && value == "afiseaza") {
			parse_print_statement(tokens, idx, ASTb); // parse print statement
		} else if (type == "KEYWORD" && value == "citeste") {
			parse_input_statement(tokens, idx, ASTb); // parse input statement */
		} else if (type == "ID" && find(parser_variables.begin(),parser_variables.end(),value)!= parser_variables.end()) {
			parse_assignment_statement(tokens, idx, ASTb); // parse print statement
		} else if (type == "ID" && (stdlib.find(value) != stdlib.end()||find(parser_user_defined_fn.begin(),parser_user_defined_fn.end(),value)!=parser_user_defined_fn.end())) {
			parse_fc_statement(tokens, idx, ASTb); // parse FC statement
		} else if (type == "KEYWORD" && value == "functie") {
			parse_fd_statement(tokens,idx,ASTb); // parse FunctionDeclaration statement
		} else if (type == "KEYWORD" && value == "returneaza") {
			parse_return_statement(tokens, idx, ASTb); // parse return statement
		} else if (type == "KEYWORD" && value == "daca") {
			parse_if_statement(tokens, idx, ASTb); // parse if statement
		} else if (type == "KEYWORD" && value == "cat") {
			parse_while_statement(tokens, idx, ASTb); // parse while statement
		} else if (type == "KEYWORD" && value == "pentru") {
			parse_for_statement(tokens, idx, ASTb); // parse for statement
		} else if (type == "KEYWORD" && value == "repeta") {
			parse_do_statement(tokens, idx, ASTb); // parse do statement
		} else {
			throw Error(
				colorize("Eroare de parsare 002: ", Color::Red, 0) + 
				"Token neasteptat: '" + value + "'",
				CURRENT_FILE,
				tokens[idx].line_nb,
				tokens[idx].line);
			idx++; // skip the unexpected token
		}
	}

	return ASTb;
}
